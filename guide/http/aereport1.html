<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>DATA | favorhau的随笔</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/logo.png">
    <meta name="description" content="favorhau">
    
    <link rel="preload" href="/assets/css/0.styles.05b5a4f8.css" as="style"><link rel="preload" href="/assets/js/app.02681985.js" as="script"><link rel="preload" href="/assets/js/2.de1ff954.js" as="script"><link rel="preload" href="/assets/js/20.f4ea8b56.js" as="script"><link rel="prefetch" href="/assets/js/10.155849ec.js"><link rel="prefetch" href="/assets/js/11.efc31f36.js"><link rel="prefetch" href="/assets/js/12.d0b5a2de.js"><link rel="prefetch" href="/assets/js/13.82fc6fc7.js"><link rel="prefetch" href="/assets/js/14.73268a60.js"><link rel="prefetch" href="/assets/js/15.1cda9909.js"><link rel="prefetch" href="/assets/js/16.6c393d95.js"><link rel="prefetch" href="/assets/js/17.e521e3ee.js"><link rel="prefetch" href="/assets/js/18.ffdc65b5.js"><link rel="prefetch" href="/assets/js/19.a1573b6c.js"><link rel="prefetch" href="/assets/js/21.b5affafe.js"><link rel="prefetch" href="/assets/js/22.1db33c57.js"><link rel="prefetch" href="/assets/js/23.61f67fc0.js"><link rel="prefetch" href="/assets/js/24.f231101c.js"><link rel="prefetch" href="/assets/js/25.fd7f1804.js"><link rel="prefetch" href="/assets/js/26.15f59fe3.js"><link rel="prefetch" href="/assets/js/27.9a18b239.js"><link rel="prefetch" href="/assets/js/28.83e6c8a2.js"><link rel="prefetch" href="/assets/js/29.b4958f19.js"><link rel="prefetch" href="/assets/js/3.de4aad32.js"><link rel="prefetch" href="/assets/js/30.c5c32088.js"><link rel="prefetch" href="/assets/js/31.d2615163.js"><link rel="prefetch" href="/assets/js/32.4cedcdc4.js"><link rel="prefetch" href="/assets/js/33.2a2d8dc8.js"><link rel="prefetch" href="/assets/js/34.58d925a1.js"><link rel="prefetch" href="/assets/js/4.5c2554a9.js"><link rel="prefetch" href="/assets/js/5.c536c2f4.js"><link rel="prefetch" href="/assets/js/6.41f85f5f.js"><link rel="prefetch" href="/assets/js/7.de80cca0.js"><link rel="prefetch" href="/assets/js/8.59406a95.js"><link rel="prefetch" href="/assets/js/9.4b66b608.js">
    <link rel="stylesheet" href="/assets/css/0.styles.05b5a4f8.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">favorhau的随笔</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/art.html" class="nav-link">
  视觉传达
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/art.html" class="nav-link">
  视觉传达
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>机器学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/guide/ml/aereport1.html" class="sidebar-link">机器学习任务</a></li><li><a href="/guide/ml/note.html" class="sidebar-link">机器学习相关库</a></li><li><a href="/guide/ml/pileline.html" class="sidebar-link">深度学习</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Javascript</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>HTTP</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>C++</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Python</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据库</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据结构</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="data"><a href="#data" class="header-anchor">#</a> DATA</h2> <h3 id="keyword"><a href="#keyword" class="header-anchor">#</a> keyword</h3> <p>GANs are structured probabilistic model.</p> <p>A two-player minimax game</p> <h3 id="gans-components"><a href="#gans-components" class="header-anchor">#</a> GANS components</h3> <ul><li>network architecture</li> <li>objective funtion</li> <li>optimization algorithm</li></ul> <h3 id="black-stickers"><a href="#black-stickers" class="header-anchor">#</a> black stickers</h3> <p>使用所提出的算法，我们评估了扰动对物理对象的有效性，并表明对手可以使用低成本技术对对象进行物理修改，从而在距离和角度变化很大的情况下，在基于DNN的分类器中可靠地导致分类错误。例如，我们的攻击导致分类器将经过细微修改的物理停车标志分类为限速45标志。具体来说，我们的最终扰动形式是一组黑白贴纸，对手可以将这些贴纸贴在物理路标上(停车标志)。我们设计的扰动类似涂鸦，这是一种相对常见的破坏形式。如图1所示，在现实世界中经常会看到带有随机涂鸦或颜色变化的路标(左边的图像是城市中的真实路标)。如果这些随机模式是对抗性扰动(图1的右侧展示了扰动示例)，它们可能会给自动驾驶系统带来严重后果，但不会引起操作员的怀疑。</p> <h3 id="fgsm"><a href="#fgsm" class="header-anchor">#</a> FGSM</h3> <p>The FGSM algorithm was proposed by Goodfellow
et al. [9]. In the paper, the researchers believe that the rea
son for adversarial examples is the linear characteristics of
deep neural networks in high-dimensional space.
FGSM是一种一次攻击，即针对一张图加梯度也仅仅增一次梯度。但如果现在攻击的是一个复杂非线性模型的话，这样的方法可能就不能一定攻击成功。可以想象，复杂的非线性模型可能在极小的范围内剧烈变化，所以梯度跨度大可能就不能攻击成功</p> <h3 id="digital-real-world-attack"><a href="#digital-real-world-attack" class="header-anchor">#</a> digital &amp; real world attack</h3> <p>In the digital world, the attacker has “digital level” access</p> <p>to the input. For example, the attacker can make arbitrary</p> <p>pixel-level modifcations to the input image of the classifer.</p> <p>However, in real applications, attackers cannot control the</p> <p>sensors and data pipes of the system.</p> <h3 id="attack-and-defense"><a href="#attack-and-defense" class="header-anchor">#</a> attack and defense</h3> <p><strong>5.1 Attack direction</strong></p> <p>Just like the analysis in the third part, for the same attack</p> <p>task in diferent scenarios, the attacker needs to design</p> <p>diferent perturbation deployment schemes to achieve the</p> <p>attack. This is also a key step in applying adversarial sam</p> <p>ples to the actual physical world. Then, if we can generate</p> <p>a universal and adaptive perturbation deployment plan, the</p> <p>attack may be more efcient.</p> <p>The current attack methods are often only targeted at a</p> <p>certain sensor. But in some actual devices, there are often</p> <p>multiple sensors, such as multi-cameras. So whether it is</p> <p>possible to generate a suitable disturbance deployment plan</p> <p>to deceive multiple sensors at the same time, this may be a</p> <p>direction worth exploring.</p> <p>In addition, in some felds, there are often many difer</p> <p>ent sensors. For example, in the feld of autonomous driv</p> <p>ing, the input data of the model includes not only the data</p> <p>captured by the camera but also the data captured by the</p> <p>LiDAR. Therefore, can we generate a suitable perturbation</p> <p>deployment plan and deceive the camera and LiDAR at the</p> <p>same time. This may be a direction worth exploring for the</p> <p>attacker in the future.</p> <p><strong>5.2 Defense direction</strong></p> <p>We believe that by continuously improving computer perfor</p> <p>mance, we can efectively alleviate the current adversarial</p> <p>training problems and greatly reduce the execution time. The</p> <p>goal of an adversarial attack is the model hidden behind the</p> <p>system. If the system’s dependence on the model can be</p> <p>reduced, this may enhance the model’s defesnse capabilities.</p> <p>As analyzed in the fourth part, the feasible defense</p> <p>methods in the physical world are mainly robust learning</p> <p>and perturbation detection. These defense methods have</p> <p>been proven efective in attacks in the digital world. Then,</p> <p>whether other feasible defense methods in the digital world</p> <p>can be adapted to the physical world through a certain trans</p> <p>formation, this may also be a direction worthy of research</p> <p>for defenders.</p> <h2 id="report"><a href="#report" class="header-anchor">#</a> Report</h2> <h3 id="topics"><a href="#topics" class="header-anchor">#</a> Topics</h3> <ul><li><p>欢迎词</p></li> <li><p>自我介绍，简述调研当中所作的工作</p></li></ul> <p>论文 综述 交流 简单的框架实战</p> <h3 id="summarize-the-text"><a href="#summarize-the-text" class="header-anchor">#</a> Summarize the text</h3> <ul><li><p>表述内容重点有关调研</p> <p>实际应用中有哪些类型对抗样本？在物理世界对抗样本方法调研和问题分类</p> <p>研究背景 实际方法的分类 和想要与大家分享的一篇paper</p></li></ul> <h3 id="analysis-background"><a href="#analysis-background" class="header-anchor">#</a> Analysis background</h3> <ul><li>自动驾驶的事故</li></ul> <p>制约行业发展</p> <ul><li>熊图</li></ul> <p><em>Deep neural networks (DNNs) are vulnerable to adversarial
examples where inputs with imperceptible perturbations mislead DNNs to incorrect results.</em></p> <p>FGSM</p> <ul><li>CNN需要具有鲁棒性</li></ul> <p><em>they bring serious security risks to deep-learning-based systems.</em></p> <ul><li>物理世界中也存在对抗样本</li></ul> <p><em>adversarial examples exist not only in the digital world, but also in the physical world</em></p> <p>打印照片 高置信度误差</p> <h3 id="categories"><a href="#categories" class="header-anchor">#</a> categories</h3> <ul><li>大致分类 而不能进行精准分类</li></ul> <p>简述分类方法</p> <ul><li>FGSM</li></ul> <p>经典梯度下降方法 FGSM</p> <p><em>the researchers believe that the rea
son for adversarial examples is the linear characteristics of
deep neural networks in high-dimensional space.</em></p> <p><em>FGSM是一种一次攻击，即针对一张图加梯度也仅仅增一次梯度。但如果现在攻击的是一个复杂非线性模型的话，这样的方法可能就不能一定攻击成功。可以想象，复杂的非线性模型可能在极小的范围内剧烈变化，所以梯度跨度大可能就不能攻击成功</em></p> <h3 id="adversarial-examples-in-physical-world"><a href="#adversarial-examples-in-physical-world" class="header-anchor">#</a> Adversarial examples in physical world</h3> <ul><li>经典论文</li></ul> <p><code>打印纸</code>printed the adversarial pictures on paper, and successfully cheated the Inception v3 model after being photographed by the camera</p> <p><code>3d变换</code>3D printed tortoise</p> <p><code>贴纸</code>一组黑白贴纸，对手可以将这些贴纸贴在物理路标上(停车标志)。我们设计的扰动类似涂鸦</p> <h3 id="difference-of-digital-physical"><a href="#difference-of-digital-physical" class="header-anchor">#</a> Difference of digital &amp; physical</h3> <p>a. Sensor viewing angle: The real physical world is in a
three-dimensional space.
b. Light: The intensity of natural light and the color of
ambient light can afect the imaging of the adversarial
examples in the sensor.
c. Distance: The size of the captured sample is afected by
the distance between the target and the sensor.</p> <h3 id="practical-application-of-the-adversary-examples"><a href="#practical-application-of-the-adversary-examples" class="header-anchor">#</a> Practical application of the adversary examples</h3> <h3 id="ps-gans"><a href="#ps-gans" class="header-anchor">#</a> PS-GANs</h3> <ul><li><p>时间关系 缩略</p></li> <li><p>感知与精神物理学结合</p></li> <li><p>GANs zero-sum game</p></li> <li><p>生成器G用于强化patch，判决器D用于判断patch是否具外观自然性</p></li> <li><p>不再是噪声而是具有意义的“涂鸦”，因此它得到的新patch，不再像其他的技术得到的patch那样有着意义不明的图案</p></li> <li><p>只需更小的distortion就能得到更好的攻击效果</p></li> <li><p>半白盒攻击情况</p></li> <li><p>不一定很理想 因为上述提到的因素</p></li> <li><p>图像的扰动对人类来说是不可见的，但对深度学习模型却是致命的，会导致错误的分类。</p></li></ul> <h3 id="future"><a href="#future" class="header-anchor">#</a> Future</h3> <ul><li>防御方面比较少</li> <li>围绕着攻击和防御开展的对抗补丁</li></ul></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.02681985.js" defer></script><script src="/assets/js/2.de1ff954.js" defer></script><script src="/assets/js/20.f4ea8b56.js" defer></script>
  </body>
</html>
